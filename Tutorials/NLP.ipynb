{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d156654",
   "metadata": {},
   "source": [
    "## NLP using NLTK in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download('punkt_tab')  \n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "# nltk.download('maxent_ne_chunker_tab')\n",
    "# nltk.download('words')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef3449",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "str= 'Hello I am Ali from Pakistan. Give me some country names.'\n",
    "\n",
    "tokens=nltk.word_tokenize(str)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecaa5bd",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= nltk.corpus.stopwords.words('english')\n",
    "sentence=\"The weather today is quite pleasant, and the sun is shining brightly in the sky. People are walking in the park, enjoying the fresh air and the warmth of the morning sun.\"\n",
    "\n",
    "filteredWords=[]\n",
    "\n",
    "for x in sentence.split(' '):\n",
    "    if x not in stop_words:\n",
    "        filteredWords.append(x)\n",
    "\n",
    "print(filteredWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4395bb",
   "metadata": {},
   "source": [
    "### Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'I am Ali. I play football'\n",
    "tokens= word_tokenize(text)\n",
    "\n",
    "pos= nltk.pos_tag(tokens)\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f13e46",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "text= \"The runners were running rapidly towards the finishing line. Each runner hoped to finish first and win the running competition. They trained daily, practicing their runs and improving their speed.\"\n",
    "\n",
    "tokens= nltk.word_tokenize(text)\n",
    "\n",
    "ps=  nltk.stem.PorterStemmer()\n",
    "\n",
    "stemmed= [ps.stem(word) for word in tokens]\n",
    "\n",
    "# print(stemmed)\n",
    "\n",
    "word= 'rapidly'\n",
    "\n",
    "print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16eaf07",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "lemmitizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "word= 'rapidly'\n",
    "\n",
    "# lemit_words= [lemmitizer.lemmatize(word) for word in tokens]\n",
    "lemit_words= lemmitizer.lemmatize(word)\n",
    "print(lemit_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be68e1",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7689ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "tokens= word_tokenize(text)\n",
    "\n",
    "pos= nltk.pos_tag(tokens)\n",
    "\n",
    "# grammar for chunking\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "#grammar for chinking\n",
    "\n",
    "# grammar = \"NP: {<.*>+}}<VB.*|IN>+{\"\n",
    "\n",
    "parser= nltk.chunk.RegexpParser(grammar)\n",
    "\n",
    "chunked= parser.parse(pos)\n",
    "\n",
    "print(chunked)\n",
    "\n",
    "# chunked.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41b905",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81866e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Barack Obama was born in Hawaii and was elected President of the United States in 2008.\"\n",
    "\n",
    "tokens= word_tokenize(text)\n",
    "\n",
    "pos_tags= nltk.pos_tag(tokens)\n",
    "\n",
    "ner= nltk.ne_chunk(pos_tags)\n",
    "\n",
    "print(ner)\n",
    "\n",
    "# ner.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b00340",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2528e7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk.stem.wordnet' has no attribute 'synsets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m syn= \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwordnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynsets\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mhappy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'nltk.stem.wordnet' has no attribute 'synsets'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "syn= nltk.WordNetLemmatizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
